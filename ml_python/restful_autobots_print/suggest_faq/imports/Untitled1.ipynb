{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NLTK IMPORTS\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "#PATTERNS\n",
    "from pattern.en import parsetree\n",
    "from pattern.en import tenses, PAST, PL\n",
    "\n",
    "#IMPORTING STUFF\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "#SCIKIT-LEARN IMPORTS\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class vectorizer():\n",
    "\tdef __init__(self):\n",
    "\t\tself.stopwords = stopwords.words('english')\n",
    "\t\tself.vec = DictVectorizer()\n",
    "        \n",
    "\tdef tenseses(self,strs):\n",
    "\t\tif 'present' in str(tenses(strs)):\n",
    "\t\t    ten = 'PRESENT'\n",
    "\t\telif 'past' in tenses(strs):\n",
    "\t\t    ten = \"PAST\"\n",
    "\t\telse:\n",
    "\t\t    ten = \"FUTURE\"\n",
    "\t\treturn ten\n",
    "\n",
    "\tdef dialogue_act_features(self,post):\n",
    "\t\tstop = nltk.word_tokenize(post)\n",
    "\t\tpost = []\n",
    "\t\tfor i in stop:\n",
    "\t\t    if i not in self.stopwords:\n",
    "\t\t\tpost.append(i)\n",
    "\t\t    else:\n",
    "\t\t\tpass\n",
    "\t\t\t#regect_list.append(i)\n",
    "\t\tposts = \"\"\n",
    "\t\tfor i in post:\n",
    "\t\t    posts += i\n",
    "\t\t    posts += \" \"\n",
    "\t\tprocessed = parsetree(posts, relations=True, lemmata=True)\n",
    "\t\tfeatures = {}\n",
    "\t\tfor sents in processed:\n",
    "\t\t    x = sents\n",
    "\t\t    for i in x.chunks:\n",
    "\t\t\tj = i.pos\n",
    "\t\t\tif j == \"VP\":\n",
    "\t\t\t    tense = self.tenseses(i.string)\n",
    "\t\t\telse:\n",
    "\t\t\t    tense = \"\"\n",
    "\t\t\th = i.words\n",
    "\t\t\tfor words in h:\n",
    "\t\t\t    apd_str =  str(words.lemma) +\"-\"+ str(words.pos)\n",
    "\t\t\t    #+ \"-\" +tense\n",
    "\t\t\t    #if words.pos[:1] == \"NN\" or words.pos[:1] == \"VP\":\n",
    "\t\t\t    features['word({})'.format(str(words.lemma))] =  str(words.pos)\n",
    "\t\t\t#pos['features({})'.format(j)] = True\n",
    "\t\t    return features\n",
    "\tdef vectorize(self,feat_list):\n",
    "\t\tpos_vectorized = self.vec.fit_transform(feat_list)\n",
    "\t\treturn pos_vectorized\n",
    "\tdef reVectorize(self,feat_list):\n",
    "\t\tpos_vectorized = self.vec.transform(feat_list)\n",
    "\t\treturn pos_vectorized\n",
    "\tdef train_gen(self,x):\n",
    "\t    iterations = []\n",
    "\t    for i in x:\n",
    "\t\t#print\n",
    "\t\tm1 = i[0]\n",
    "\t\tm1.reverse()\n",
    "\t\tx1 = i[1]\n",
    "\t\tx1.reverse()\n",
    "\t\twhile True:\n",
    "\t\t    if len(x1) == 0 and len(m1) == 0:\n",
    "\t\t\tbreak\n",
    "\t\t    temp = []\n",
    "\t\t    temp2 = []\n",
    "\t\t    while True:\n",
    "\t\t\ttry:\n",
    "\t\t\t    temp.append(m1.pop())\n",
    "\t\t\t    #print temp[-1]\n",
    "\t\t\t    if temp[1] == 0:\n",
    "\t\t\t        break\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t    break\n",
    "\t\t    while True:\n",
    "\t\t\ttry:\n",
    "\t\t\t    temp2.append(x1.pop())\n",
    "\t\t\t    #print temp2[-1]\n",
    "\t\t\t    if temp2[-1][1] == 0:\n",
    "\t\t\t        break\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t    break\n",
    "\t\t    #print len(x1)\n",
    "\t\t    me_str = \"\"\n",
    "\t\t    m_str = \"\" \n",
    "\t\t    for i in temp:\n",
    "\t\t\tme_str += \" \"\n",
    "\t\t\tme_str += i[0]\n",
    "\t\t    for i in temp2:\n",
    "\t\t\tm_str += i[0]\n",
    "\t\t    iterations.append((self.dialogue_act_features(me_str),m_str))\n",
    "\t    x = []\n",
    "\t    y = []\n",
    "\t    for i in iterations:\n",
    "\t    \t  x.append(i[0])\n",
    "\t    \t  y.append(i[1])\n",
    "\t    return_dictionary_buffer = {}\n",
    "\t    return_dictionary_buffer['x'] = x\n",
    "\t    return_dictionary_buffer['y'] = y  \n",
    "\t    return return_dictionary_buffer\n",
    "\n",
    "def dict_builder(y):\n",
    "    count = 0\n",
    "    indexDict = {}\n",
    "    reverseDict = {}\n",
    "    indexList = []\n",
    "    for i in y:\n",
    "        try:\n",
    "            indexList.append(reverseDict[i])\n",
    "        except Exception as e:\n",
    "            indexList.append(count)\n",
    "            reverseDict[i] = count\n",
    "            count += 1\n",
    "    for i in reverseDict:\n",
    "        indexDict[reverseDict[i]] = i\n",
    "    return (indexList,indexDict) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class predictions():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vectors = vectorizer()\n",
    "        \n",
    "    #get the vector for predictions\n",
    "    def get_predict_vector(self,string):\n",
    "        return self.vectors.reVectorize(self.vectors.dialogue_act_features(string))\n",
    "    \n",
    "    def get_val_for_index(self,array):\n",
    "        for i in array:\n",
    "            www = self.index_to_val[i]\n",
    "        return www\n",
    "    \n",
    "    def predict(self,string):\n",
    "        vector = self.get_predict_vector(string)\n",
    "        res = self.clf.predict(vector)\n",
    "        return self.get_val_for_index(res)\n",
    "    \n",
    "    def learn(self,x):8\n",
    "        temp = self.vectors.train_gen(x)\n",
    "        X = self.vectors.vectorize(temp['x'])\n",
    "        Y,self.index_to_val = dict_builder(temp['y'])\n",
    "        self.clf = LinearSVC().fit(X, Y)\n",
    "    def learn_from_db(self,x,xy_list):\n",
    "        temp = self.vectors.train_gen(x)\n",
    "        for i in xy_list['x']:\n",
    "            temp['x'].append(self.vectors.dialogue_act_features(i))\n",
    "        for i in xy_list['y']:\n",
    "            temp['y'].append(i)\n",
    "        X = self.vectors.vectorize(temp['x'])\n",
    "        Y,self.index_to_val = dict_builder(temp['y'])\n",
    "        self.clf = LinearSVC().fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c0c1475037dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpredictors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn_from_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxy_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predictors' is not defined"
     ]
    }
   ],
   "source": [
    "x = [[[[u'save', 0]], []]]\n",
    "\n",
    "\n",
    "predictors.learn_from_db(x,xy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector = vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DictVectorizer(dtype=<type 'numpy.float64'>, separator='=', sort=True,\n",
      "        sparse=True)\n"
     ]
    }
   ],
   "source": [
    "print vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
